{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8552ca2-b15c-4b4c-9c0c-f3fac1ef17a3",
   "metadata": {},
   "source": [
    "# Schritt 1: Vorbereitung\n",
    "\n",
    "Im folgenden werden allgemeine Funktionen definiert, die flexibel und modell- sowie datensatzunabhängig sind. Diese Funktionen sind so konzipiert, dass sie auf verschiedene Modelle und Datensätze angewendet werden können, ohne dass spezifische Anpassungen für jedes Modell oder jeden Datensatz vorgenommen werden müssen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f269e0b-034d-4dd1-8a71-aaae96414f11",
   "metadata": {},
   "source": [
    "## Pakete importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1aeb44dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1282044415.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[272], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install --upgrade tensorflow\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install liac-arff\n",
    "%pip install tslearn\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install tensorflow\n",
    "%pip install tqdm\n",
    "%pip install tslearn.neighbors\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install pyts\n",
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86be2cd-9a29-433c-ba1a-2dd1aa35e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance\n",
    "from pyts.transformation import ShapeletTransform\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tslearn.utils import to_sklearn_dataset\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tslearn.datasets import UCR_UEA_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5b461-07ad-4146-a952-9393ac22e2c2",
   "metadata": {},
   "source": [
    "## Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf91e5-7f96-4817-8a8c-ecebb29ec101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Laden der Daten über tslearn und Reshaping der Dimensionen\n",
    "def read_data(DS):\n",
    "    # Lade den Datensatz über die tslearn-Bibliothek\n",
    "    ucr = UCR_UEA_datasets()\n",
    "    X_train, y_train, X_test, y_test = ucr.load_dataset(DS)\n",
    "    \n",
    "    # Überprüfe, ob die Eingabedaten mehrdimensional sind (z.B. 3D) und flache sie auf 2D ab\n",
    "    if X_train.ndim == 3:\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
    "    if X_test.ndim == 3:\n",
    "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
    "    \n",
    "    # Wandle die Labels in Integer-Klassen um\n",
    "    y_train, y_test = label_encoder(y_train, y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0886e-84c8-4587-a17c-349e85fa5069",
   "metadata": {},
   "source": [
    "## Datenvorbereitung\n",
    "\n",
    "Die Funktion label_encoder wird verwendet, um die Labels der Trainings- und Testdaten in Ganzzahlen (Integer) zu kodieren.\n",
    "\n",
    "Gründe:\n",
    "- Maschinenlernalgorithmen arbeiten mit numerischen Werten (Datensätze mit Text oder Kategorien werden umgewandlet)\n",
    "- Um sicherzustellen, dass die gleichen Kategorien in den Trainings- und Testdaten gleich behandelt werden, wird der LabelEncoder auf die kombinierten Trainings- und Testdaten angepasst. Dadurch werden alle Kategorien erkannt und entsprechend kodiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd1472-ec40-4182-b804-d25d529f7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Kodieren der Labels als Ganzzahlen\n",
    "def label_encoder(training_labels, testing_labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(np.concatenate((training_labels, testing_labels), axis=0))\n",
    "    y_train = le.transform(training_labels)\n",
    "    y_test = le.transform(testing_labels)\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d254b8-581b-41f4-afa4-fb9a89690a55",
   "metadata": {},
   "source": [
    "## Muster identifizieren\n",
    "\n",
    "Die Kombination der beiden folgenden Funktionen erlaubt es, aus Zeitreihen charakteristische Muster zu extrahieren, die spezifisch für bestimmte Klassen sind, was für die Klassifikation nützlich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e1760b-ebe8-4eb8-928d-6815fd06d742",
   "metadata": {},
   "source": [
    "Diese Funktion ist für die Extraktion von Shapelets aus den Trainingsdaten verantwortlich. Shapelets sind kurze, charakteristische Muster, die in den Zeitreihen vorkommen und zur Klassifikation verwendet werden können\n",
    "\n",
    "Initialisierung des Shapelet-Transformationsmodells:\n",
    "\n",
    "Das Modell ShapeletTransform wird erstellt. Die wichtigsten Parameter sind:\n",
    "n_shapelets=100: Extrahiere 100 Shapelets aus den Zeitreihen.\n",
    "window_sizes=[a, b, c]: Verwende die zuvor berechneten Fenstergrößen, um Shapelets verschiedener Längen zu extrahieren.\n",
    "random_state=42: Dies sorgt dafür, dass die zufällige Auswahl von Shapelets in verschiedenen Läufen des Codes gleich bleibt (Reproduzierbarkeit).\n",
    "sort=True: Sortiere die extrahierten Shapelets nach ihrer Wichtigkeit\n",
    "\n",
    "Anpassung und Transformation des Modells:\n",
    "\n",
    "st.fit_transform(X_train, y_train) passt das Shapelet-Transformationsmodell an die Trainingsdaten an.\n",
    "Es analysiert die Zeitreihen X_train und die zugehörigen Labels y_train, um 100 Shapelets zu extrahieren, die am besten zwischen den Klassen unterscheiden.\n",
    "\n",
    "Extraktion der Shapelet-Indizes:\n",
    "\n",
    "Nachdem das Shapelet-Transformationsmodell angepasst wurde, werden die Indizes der extrahierten Shapelets gespeichert. Diese Indizes enthalten Informationen darüber, an welcher Position jedes Shapelet in den ursprünglichen Zeitreihen gefunden wurde.\n",
    "Diese Indizes werden in einem pandas.DataFrame gespeichert und zurückgegeben.\n",
    "\n",
    "--> Diese Funktion extrahiert Shapelets, die charakteristische Muster in den Zeitreihen darstellen und zur Klassifikation verwendet werden können. Sie passt ein Shapelet-Transformationsmodell an und gibt die Indizes der extrahierten Shapelets zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0620a0-9083-4444-b033-27f11b9fce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tslearn\n",
    "import pandas as pd\n",
    "\n",
    "def get_shapelet(X_train, y_train, len_ts):\n",
    "    # Define window sizes for shapelets\n",
    "    a = int(len_ts * 0.3)\n",
    "    b = int(len_ts * 0.5)\n",
    "    c = int(len_ts * 0.7)\n",
    "    \n",
    "    # Initialize ShapeletTransform\n",
    "    st = ShapeletTransform(n_shapelets=100, window_sizes=[a, b, c], random_state=42, sort=True)\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_transformed = st.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Extract indices of shapelets\n",
    "    indices = pd.DataFrame(st.indices_)\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9c571-96d5-437d-a74f-e3a9aa2294ce",
   "metadata": {},
   "source": [
    "Diese Funktion kategorisiert die extrahierten Shapelets basierend auf ihren zugehörigen Klassenlabels. Sie filtert die Shapelets für eine bestimmte Klasse heraus.\n",
    "\n",
    "Schritt-für-Schritt-Erklärung:\n",
    "Extraktion der Labels der Shapelets:\n",
    "\n",
    "Die Funktion verwendet die Indizes der Shapelets, um die zugehörigen Klassenlabels aus y_train zu extrahieren.\n",
    "indices.iloc[:, 0] liefert die Indizes der Zeitreihen, aus denen die Shapelets extrahiert wurden. Diese Indizes werden verwendet, um die zugehörigen Labels aus y_train zu erhalten.\n",
    "\n",
    "Erstellen eines DataFrames für die Labels:\n",
    "\n",
    "Die extrahierten Labels werden in ein pandas.DataFrame konvertiert, damit sie später mit den Shapelet-Indizes kombiniert werden können.\n",
    "\n",
    "Kombinieren der Shapelet-Indizes und Labels:\n",
    "\n",
    "Die Shapelet-Indizes und die zugehörigen Labels werden zu einem einzigen DataFrame zusammengeführt.\n",
    "Dieser DataFrame hat vier Spalten:\n",
    "- idx: Index der Zeitreihe, aus der das Shapelet stammt.\n",
    "- start_point: Startpunkt des Shapelets in der Zeitreihe.\n",
    "- end_point: Endpunkt des Shapelets in der Zeitreihe.\n",
    "- label: Klassenlabel des Shapelets.\n",
    "\n",
    "Gruppieren nach Labels:\n",
    "\n",
    "Der DataFrame wird nach dem Klassenlabel gruppiert. Dies ist nützlich, um Shapelets zu filtern, die zu einer bestimmten Klasse gehören.\n",
    "\n",
    "Filtern der Shapelets für eine bestimmte Klasse:\n",
    "\n",
    "Die Funktion filtert die Shapelets für die angegebene Klasse label. Sie gibt die ersten Shapelets zurück, die zu dieser Klasse gehören.\n",
    "\n",
    "Konvertieren des Ergebnisses in ein NumPy-Array:\n",
    "\n",
    "Schließlich wird das Ergebnis in ein NumPy-Array umgewandelt, um es einfacher weiterverarbeiten zu können.\n",
    "\n",
    "--> Diese Funktion kategorisiert die extrahierten Shapelets basierend auf den Klassenlabels der Trainingsdaten. Sie filtert die Shapelets für eine bestimmte Klasse heraus und gibt die relevanten Shapelets zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3523b51-03d4-4e9c-bc2d-a41ca4c92f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Kategorisierung der Shapelets basierend auf den Labels\n",
    "def shapelet_category(y_train, indices, label):\n",
    "    labels = y_train[indices.iloc[:, 0]]\n",
    "    labels = pd.DataFrame(labels)\n",
    "    frames = [indices, labels]\n",
    "    res = pd.concat(frames, axis=1)\n",
    "    res.columns = [\"idx\", \"start_point\", \"end_point\", \"label\"]\n",
    "    res = res.groupby('label')\n",
    "    res = res.get_group(label).head(1)\n",
    "    res = np.array(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f9c3c-4414-4b95-95ee-08b3eec5d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Plotten der Shapelets\n",
    "def plot_shapelet(X_train, shapelets, cls, save_path=None):\n",
    "    plt.style.use('bmh')\n",
    "    \n",
    "    # Plot der gesamten Zeitreihe und des Shapelets\n",
    "    plt.plot(X_train[shapelets[cls][0][0]], )\n",
    "    plt.plot(np.arange(shapelets[cls][0][1], shapelets[cls][0][2]),\n",
    "             X_train[shapelets[cls][0][0], shapelets[cls][0][1]:shapelets[cls][0][2]], label=\"shapelet\")\n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.title('The shapelets for class ' + str(cls), fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Speichere das Diagramm oder zeige es an\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a51d4-540e-49ae-9c8f-51ae5650598a",
   "metadata": {},
   "source": [
    "## Modell\n",
    "\n",
    "Training eines beliebigen Modells.\n",
    "\n",
    "- Das Modell wird durch die Funktion train_model() trainiert. Das spezifische Modell wird durch den Parameter classifier bestimmt. Es könnte ein beliebiges Machine-Learning-Modell sein, das in Scikit-learn verwendet werden kann (z.B. Random Forest, SVM, etc.).\n",
    "- Die Funktion target() zielt darauf ab, die zweitwahrscheinlichste Klasse zu bestimmen.\n",
    "- targets_generation() verwendet die zweitwahrscheinlichste Klasse als Ziel.\n",
    "- eval_model() berechnet die Genauigkeit des Modells auf den Testdaten.\n",
    "\n",
    "Der Code gibt dir die Flexibilität, verschiedene Klassifikatoren zu verwenden und unterschiedliche Ziele zu betrachten (wie z.B. die zweitwahrscheinlichste Klasse).\n",
    "\n",
    "Trainieren des Modells:\n",
    "- Die Funktion train_model(classifier, X_train, y_train, X_test) nimmt einen vorkonfigurierten Klassifikator (classifier) als Eingabe entgegen.\n",
    "- Das Modell wird mit den Daten (X_train, y_train) trainiert, indem die Methode fit() aufgerufen wird.\n",
    "- Da der Klassifikator als Parameter übergeben wird, kann es sich um beliebige Modelle handeln, die mit fit() trainiert werden können, z.B. RandomForestClassifier, SVC, KNeighborsClassifier, usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9114e99-9462-4981-8e7f-251188916b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Trainieren des Klassifikators\n",
    "#def train_model(classifier, X_train, y_train, X_test):\n",
    "#    model = classifier\n",
    "#    model.fit(X_train, y_train)\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64eb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_train, y_train, X_test):\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # Assuming you're using the same architecture for encoder/decoder in the autoencoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    x = keras.layers.Conv1D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu')(encoder_input)\n",
    "    x = keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = keras.layers.Conv1D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    encoder_output = keras.layers.Dense(50, activation='relu')(x)\n",
    "    encoder = keras.Model(inputs=encoder_input, outputs=encoder_output, name=\"encoder\")\n",
    "\n",
    "    intermediate_shape = (input_shape[0] // 4, 8)\n",
    "    \n",
    "    decoder_input = keras.Input(shape=(50,))\n",
    "    x = keras.layers.Dense(np.prod(intermediate_shape), activation='relu')(decoder_input)\n",
    "    x = keras.layers.Reshape(intermediate_shape)(x)\n",
    "    x = keras.layers.Conv1DTranspose(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = keras.layers.Conv1DTranspose(filters=16, kernel_size=5, strides=2, padding='same', activation='relu')(x)\n",
    "    decoder_output = keras.layers.Conv1DTranspose(filters=input_shape[1], kernel_size=5, padding='same')(x)\n",
    "    decoder = keras.Model(inputs=decoder_input, outputs=decoder_output, name=\"decoder\")\n",
    "\n",
    "    # Combine encoder and decoder to form autoencoder\n",
    "    autoencoder = keras.Model(inputs=encoder_input, outputs=decoder(encoder_output))\n",
    "    autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "\n",
    "    # Train autoencoder (if required)\n",
    "    autoencoder.fit(X_train, X_train, epochs=20, batch_size=1, validation_split=0.1)\n",
    "\n",
    "    # Use encoder to transform X_train for classifier training\n",
    "    X_train_encoded = encoder.predict(X_train)\n",
    "    classifier.fit(X_train_encoded, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # You can now use the trained encoder and classifier to make predictions\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9096b8-e516-454c-abc8-751a73334958",
   "metadata": {},
   "source": [
    "Bestimmen des Ziels mit der Funktion target:\n",
    "\n",
    "Die Funktion target(instance) nimmt eine Array von Wahrscheinlichkeiten (z. B. die vorhergesagten Klassenwahrscheinlichkeiten) als Eingabe und gibt den Index des zweitgrößten Wertes zurück.\n",
    "np.argsort(instance)[-2:-1][0] sortiert die Wahrscheinlichkeiten und gibt den Index des zweitgrößten Wertes zurück.\n",
    "Dies könnte nützlich sein, wenn du das Modell daraufhin bewerten möchtest, wie gut es die zweitwahrscheinlichste Klasse vorhersagt.\n",
    "\n",
    "\n",
    "Generieren der Ziele basierend auf Wahrscheinlichkeiten (targets_generation):\n",
    "\n",
    "Die Funktion targets_generation(y_preds) durchläuft die vorhergesagten Wahrscheinlichkeiten y_preds für alle Testinstanzen und verwendet die target()-Funktion, um die zweitwahrscheinlichsten Klassen für jede Instanz zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0005b6-59d6-4e2c-809c-420c16f9101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion zur Bestimmung des zweitgrößten Wertes (Ziel)\n",
    "def target(instance):\n",
    "    target = np.argsort(instance)[-2:-1][0]\n",
    "    print('target')\n",
    "    return target\n",
    "\n",
    "# Generiere Ziele basierend auf den vorhergesagten Wahrscheinlichkeiten\n",
    "def targets_generation(y_preds):\n",
    "    targets = []\n",
    "    print('target generation')\n",
    "    for i in y_preds:\n",
    "        res = target(i)\n",
    "        targets.append(res)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe6cb3-a2e4-47b4-b202-de4f0252035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Genauigkeit des Modells\n",
    "def eval_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db77a60-2c96-4fc7-8e26-c390111c9e6e",
   "metadata": {},
   "source": [
    "## Erstellung von Counterfactuals\n",
    "\n",
    "Eingabeparameter:\n",
    "- test_samples: Dies sind die Testdaten, die du verändern möchtest, um Gegenbeispiele zu erzeugen.\n",
    "- shapelets: Eine Liste von Shapelets, die aus den Trainingsdaten extrahiert wurden. Ein Shapelet ist ein charakteristisches Muster innerhalb einer Zeitreihe, das zur Klassifikation beiträgt.\n",
    "- targets: Eine Liste von Zielklassen (basierend auf Vorhersagen), die das Gegenbeispiel erreichen soll.\n",
    "- X_train: Die Trainingsdaten, aus denen die Shapelets extrahiert wurden.\n",
    "\n",
    "Modifikation des Testbeispiels:\n",
    "\n",
    "Das Segment des Testbeispiels zwischen den Indizes start und end wird durch das entsprechende Segment aus der Trainingszeitreihe X_train[index][start:end] ersetzt. Dadurch wird das Testbeispiel modifiziert.\n",
    "Diese Modifikation könnte dazu führen, dass das Modell das Beispiel anders klassifiziert – möglicherweise als ein anderes Ziel, das durch das Shapelet beeinflusst wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe1e66-745d-433e-a9cd-805579adcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Erzeugung von Gegenbeispielen durch Modifikation von Testdaten mit Shapelets\n",
    "def counterfacutal_generation(test_samples, shapelets, targets, X_train):\n",
    "    counterfactual_examples = []\n",
    "\n",
    "    # Schleife durch jedes Testbeispiel in test_samples\n",
    "    for i in range(len(test_samples)):\n",
    "        index, start, end = shapelets[targets[i]][0][0], shapelets[targets[i]][0][1], shapelets[targets[i]][0][2]\n",
    "        test_samples[i][start:end] = X_train[index][start:end]\n",
    "        \n",
    "        # Das modifizierte Testbeispiel (jetzt ein Gegenbeispiel) wird der Liste counterfactual_examples hinzugefügt\n",
    "        counterfactual_examples.append(test_samples[i])\n",
    "        \n",
    "    # Rückgabe der Liste mit allen modifizierten Testbeispielen \n",
    "    print('counterfactual examples')\n",
    "    print(counterfactual_examples)\n",
    "    result = np.array(counterfactual_examples)  # Convert to NumPy array if not already\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562626c-3270-40a5-9663-0004ac1bb1e5",
   "metadata": {},
   "source": [
    "## Bewertung der Counterfactuals\n",
    "\n",
    "Diese Metriken können dazu verwendet werden, um die Ähnlichkeit und Unterschiede zwischen Original- und Gegenbeispielen zu analysieren, was besonders bei der Modellbewertung und Erklärbarkeit im Machine Learning nützlich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "fcabd05e-9fcc-4fbc-882c-15702b4ff4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung verschiedener Metriken zwischen zwei Zeitreihen\n",
    "# Diese Funktion berechnet verschiedene Metriken zwischen zwei Zeitreihen oder Vektoren x1 und x2, um Unterschiede und Ähnlichkeiten zu quantifizieren.\n",
    "def getmetrics(x1, x2):\n",
    "    # Falls x1 oder x2 mehrdimensional sind, flache sie ab\n",
    "    if x1.ndim > 1:\n",
    "        x1 = x1.flatten()\n",
    "    if x2.ndim > 1:\n",
    "        x2 = x2.flatten()\n",
    "\n",
    "    # Runde die Werte von x1 und x2 auf drei Dezimalstellen\n",
    "    x1 = np.round(x1, 3)\n",
    "    x2 = np.round(x2, 3)\n",
    "\n",
    "    # Berechne die Differenz zwischen den beiden Arrays\n",
    "    l = np.round(x1 - x2, 3)\n",
    "\n",
    "    # Berechne verschiedene Distanzen (L1, L2, Chebyshev)\n",
    "    # L1-Distanz (Manhattan-Distanz): Die absolute Summe der Differenzen zwischen den beiden Arrays wird berechnet. \n",
    "    # Dies misst, wie \"weit\" die beiden Vektoren in einer \"Cityblock\"-Umgebung voneinander entfernt sind.\n",
    "    l1 = distance.cityblock(x1, x2)\n",
    "    # L2-Distanz (Euklidische Distanz): Die euklidische Distanz wird als Standard-Distanz zwischen den Vektoren berechnet.\n",
    "    # Dies misst die direkte Entfernung im Raum zwischen den beiden Vektoren.\n",
    "    l2 = np.linalg.norm(x1 - x2)\n",
    "    # L∞-Distanz (Chebyshev-Distanz): Die maximale absolute Differenz zwischen den Elementen der beiden Vektoren wird berechnet\n",
    "    # Dies misst die maximale Abweichung zwischen den beiden Vektoren\n",
    "    l_inf = distance.chebyshev(x1, x2)\n",
    "    \n",
    "    # Berechne die Sparsity (Anteil der Null-Differenzen)\n",
    "    # Sparsity ist der Anteil der Differenzelemente, die Null sind. Es wird berechnet, indem die Anzahl der Null-Differenzen durch die Länge des Vektors geteilt wird.\n",
    "    # Diese Metrik gibt an, wie viel Prozent der Elemente in x1 und x2 identisch sind.\n",
    "    sparsity = (len(l) - np.count_nonzero(l)) / len(l)\n",
    "    print(\"Sparsity:\",sparsity)\n",
    "\n",
    "    # Berechne die Anzahl der Segmente mit nicht-null-Differenzen\n",
    "    # Anzahl der Segmente in der Differenz l zu bestimmen, die ungleich Null sind. \n",
    "    # Dies gibt an, wie viele zusammenhängende Abschnitte sich zwischen x1 und x2 unterscheiden\n",
    "    segnums = get_segmentsNumber(l)\n",
    "    \n",
    "    # Gib die berechneten Metriken zurück\n",
    "    return l1, l2, l_inf, sparsity, segnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36d107-7d3c-4c08-9456-f03884f99a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion zur Bestimmung der Anzahl nicht-null Segmente\n",
    "def get_segmentsNumber(l4):\n",
    "    # flag dient als Indikator, ob sich das Array gerade in einem nicht-null Segment befindet\n",
    "    # count zählt die Anzahl der nicht-null Segmente\n",
    "    flag, count = 0, 0\n",
    "\n",
    "    # Schleife durch das Array\n",
    "    for i in range(len(l4)):\n",
    "        if l4[i:i+1][0] != 0:\n",
    "            flag = 1\n",
    "        if flag == 1 and l4[i:i+1][0] == 0:\n",
    "            count = count + 1\n",
    "            flag = 0\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396caa11-67a3-44bd-b0f4-3852a859ae58",
   "metadata": {},
   "source": [
    " Die Funktion hilft dabei, zu messen, wie effektiv die generierten Gegenbeispiele das Verhalten des Modells ändern und ob sie zu den gewünschten Ergebnissen führen.\n",
    "\n",
    "Die Funktion wird verwendet, um zu bewerten, wie erfolgreich die generierten Gegenbeispiele sind, wenn es darum geht, das Modell zu manipulieren oder dessen Verhalten zu ändern.\n",
    "- Gegenbeispiele (Counterfactuals): Diese sind modifizierte Versionen von Testbeispielen, die darauf abzielen, die Vorhersage des Modells zu ändern (z.B. von Klasse A zu Klasse B).\n",
    "- Label-Flip: Ein \"Label-Flip\" bedeutet, dass das Modell nach der Modifikation durch das Gegenbeispiel eine andere Vorhersage getroffen hat. Ziel ist es oft, das Modell dazu zu bringen, die Klasse zu ändern (flip).\n",
    "\n",
    "Die Bewertung der Gegenbeispiele zeigt, wie erfolgreich diese sind, um das Modell zu beeinflussen:\n",
    "- Erklärbarkeit: Counterfactuals werden oft verwendet, um die Entscheidungsprozesse eines Modells zu erklären. Wenn ein Gegenbeispiel das Modell dazu bringt, eine andere Entscheidung zu treffen, zeigt dies, dass das modifizierte Merkmal eine wichtige Rolle spielt.\n",
    "- Modellrobustheit: Diese Funktion kann auch verwendet werden, um zu testen, wie robust ein Modell gegenüber kleinen Veränderungen der Eingabedaten ist. Wenn sich die Vorhersagen leicht durch kleine Modifikationen ändern, könnte das Modell anfällig für Angriffe oder Manipulationen sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722fea4-65f1-4bd8-95bd-2d3c4aea1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Überprüfen, ob sich die Labels der Gegenbeispiele geändert haben\n",
    "def check_fliplabel(counterfactual_examples, model, targets):\n",
    "    # Vorhersahe der Gegenbeispiele\n",
    "    counter_res = model.predict(counterfactual_examples)\n",
    "    # Bewertung der Vorhersage\n",
    "    accuracy = eval_model(counter_res, targets)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0920ef8-3480-4dd5-8a8b-472f60d5ba88",
   "metadata": {},
   "source": [
    "#### Plotten der Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f612f-35a9-42e1-ad29-8c8ff4ce99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Plotten der ursprünglichen und gegenfaktischen Zeitreihen\n",
    "def plot_cf_vs_ori(DS, index, counterfactual_examples, save_path=None):\n",
    "    # Lade den Datensatz erneut, um die Originaldaten für den Vergleich zu erhalten\n",
    "    ucr = UCR_UEA_datasets()\n",
    "    _, _, X_test, _ = ucr.load_dataset(DS)\n",
    "    \n",
    "    # Plot der Originalzeitreihe und des Gegenbeispiels\n",
    "    plt.style.use('bmh')\n",
    "    \n",
    "    plt.plot(X_test[index], label='Original', color='magenta')\n",
    "    \n",
    "    plt.plot(counterfactual_examples[index], label='CF', ls='--', color='green')\n",
    "\n",
    "    plt.xlabel('Time', fontsize=12)\n",
    "    plt.ylabel('Value', fontsize=12)\n",
    "    plt.title(f'Counterfactual vs Original on index {index}', fontsize=14)\n",
    "    plt.legend(title=\"Legend\", loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Speichere das Diagramm oder zeige es an\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611b495-8c63-4d9e-92cf-ee41270f3a28",
   "metadata": {},
   "source": [
    "Die Funktion target_probability extrahiert die Wahrscheinlichkeiten der Zielklassen für die Gegenbeispiele, um zu analysieren, wie sicher das Modell in seinen Vorhersagen für diese modifizierten Eingabedaten ist (Hohe Wahrscheinlichkeiten bedeuten, dass das Modell sehr sicher ist, dass das Gegenbeispiel zur Zielklasse gehört). Dies ist nützlich, um die Wirksamkeit von Gegenbeispielen zu bewerten (wie erfolgrecih hat das Gegenbeispiel das Modell beienflusst) und die Modellsicherheit zu verstehen.\n",
    "\n",
    "Eingabe:\n",
    "- counter_res: Dies ist eine Liste oder ein Array von Vorhersagen des Modells in Form von Wahrscheinlichkeitsverteilungen. Jede Vorhersage ist eine Verteilung über alle möglichen Klassen, z.B. [0.2, 0.7, 0.1] für drei Klassen.\n",
    "- targets: Dies ist eine Liste von Zielklassen (z.B. [1, 0, 2]), die angibt, welche Klasse wir als Ziel für die jeweiligen Gegenbeispiele erwarten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed8c50-0f4e-4a31-a862-578eb11afe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Bestimmung der Wahrscheinlichkeit des Zielwerts\n",
    "def target_probability(counter_res, targets):\n",
    "\n",
    "    # Erstellung der Liste\n",
    "    target_probs = []\n",
    "    \n",
    "    for i in range(len(counter_res)):\n",
    "        # Berechnung Wahrschienlichkeit\n",
    "        target_prob = counter_res[i][targets[i]]\n",
    "        # Hinzufügen zur Liste\n",
    "        target_probs.append(target_prob)\n",
    "        \n",
    "    return target_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd660d44-8972-46a1-bf7e-037028379f21",
   "metadata": {},
   "source": [
    "Die Funktion cf_eval_res wird verwendet, um eine umfassende Bewertung der Gegenbeispiele durchzuführen und diese Ergebnisse für eine spätere Analyse zu speichern. \n",
    "\n",
    "Diese Bewertung umfasst:\n",
    "- Berechnung verschiedener Metriken\n",
    "- Bewertung der Modellveränderung (Qualität der Gegenbeispiele, Modellgenauigkeit -> Flip-Rate)\n",
    "- Out-of-Distribution-Erkennungsmetriken (Gegenbeispiele nicht zu \"unrealistisch\" oder außerhalb der Trainingsverteilung liegen)\n",
    "\n",
    "Es handelt sich um eine umfassende Evaluierung der generierten Gegenbeispiele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "89efab8f-3f8e-4edc-b3b9-8d76ce3090a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Bewertung der Ergebnisse der Gegenbeispiele\n",
    "def cf_eval_res(DS, method, model, accuracy, counterfactual_examples, targets, target_probs):\n",
    "    \n",
    "    # Lade die Trainings- und Testdaten\n",
    "    ucr = UCR_UEA_datasets()\n",
    "    X_train, _, X_test, _ = ucr.load_dataset(DS)\n",
    "    \n",
    "    # Berechne Metriken für jedes Beispiel im Testdatensatz\n",
    "    res = []\n",
    "    for i in range(len(X_test)):\n",
    "        l1, l2, l_inf, sparsity, segnums = getmetrics(X_test[i], counterfactual_examples[i])\n",
    "        res.append([l1, l2, l_inf, sparsity, segnums, target_probs[i]])\n",
    "    \n",
    "    # Wandle die Ergebnisse in ein Array um und berechne Mittelwert und Standardabweichung\n",
    "    res_array = np.array(res)\n",
    "    mean_values = np.mean(res_array, axis=0)\n",
    "    std_values = np.std(res_array, axis=0)\n",
    "    \n",
    "    # Speichere die berechneten Metriken in einer CSV-Datei\n",
    "    summary_df = pd.DataFrame({'mean': mean_values, 'std': std_values},\n",
    "                              index=['l1', 'l2', 'l_inf', 'sparsity', 'segnums', 'target_probs'])\n",
    "    summary_df.to_csv(f'{DS}_{method}_summary.csv', index=True)\n",
    "    \n",
    "    # Überprüfe die Raten von \"Label-Flips\"\n",
    "    flip_rate = check_fliplabel(counterfactual_examples, model, targets)\n",
    "    \n",
    "    # Berechne OOD (Out-of-Distribution) Ergebnisse basierend auf LOF und SVM\n",
    "    # Diese Erkennung stellt sicher, dass die Gegenbeispiele weiterhin innerhalb der Verteilung der Trainingsdaten liegen und keine Ausreißer sind\n",
    "    OOD_svm, OOD_lof, mean_OOD_ifo = cf_ood(X_train, counterfactual_examples)\n",
    "    \n",
    "    # Speichere zusätzliche Informationen in derselben CSV-Datei\n",
    "    additional_info_df = pd.DataFrame({\n",
    "        'Flip_Label_Rate': [flip_rate],\n",
    "        'Model_Accuracy': [accuracy],\n",
    "        'OOD_SVM': [OOD_svm],\n",
    "        'OOD_LOF': [OOD_lof],\n",
    "        'OOD_IFO': [mean_OOD_ifo],\n",
    "    })\n",
    "    additional_info_df.to_csv(f'{DS}_{method}_summary.csv', mode='a', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f0b33-0b0e-4443-8694-b60e1e62c04c",
   "metadata": {},
   "source": [
    "Die Funktion cf_ood stellt sicher, dass die generierten Gegenbeispiele nicht zu unplausiblen Ausreißern werden, die außerhalb der Verteilung der Trainingsdaten liegen. Dafür werden drei Methoden verwendet:\n",
    "- LOF: Er identifiziert Punkte, die sich signifikant von ihren Nachbarn unterscheiden\n",
    "- OneClassSVM: Es lernt eine Trennlinie oder Trennfläche, um normale Datenpunkte zu identifizieren und neuartige oder unbekannte Punkte als Ausreißer zu markieren\n",
    "- Isolation Forrest: Er isoliert Datenpunkte, die weit von der Mehrheit entfernt liegen, und identifiziert sie als Ausreißer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050efe91-abb7-46d5-8ed8-16b4600ffd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Bewertung von Gegenbeispielen mittels LOF, SVM und Isolation Forest (OOD)\n",
    "def cf_ood(X_train, counterfactual_examples):\n",
    "    \n",
    "    # Lokaler Ausreißerfaktor (LOF) zur Erkennung von Ausreißern\n",
    "    lof = LocalOutlierFactor(n_neighbors=int(np.sqrt(len(X_train))), novelty=True, metric='euclidean')\n",
    "    lof.fit(to_sklearn_dataset(X_train))\n",
    "    novelty_detection = lof.predict(to_sklearn_dataset(counterfactual_examples))\n",
    "    OOD_lof = np.count_nonzero(novelty_detection == -1) / len(counterfactual_examples)\n",
    "    \n",
    "    # Ein-Klassen-SVM zur Erkennung von Ausreißern\n",
    "    clf = OneClassSVM(gamma='scale', nu=0.02).fit(to_sklearn_dataset(X_train))\n",
    "    novelty_detection = clf.predict(to_sklearn_dataset(counterfactual_examples))\n",
    "    OOD_svm = np.count_nonzero(novelty_detection == -1) / len(counterfactual_examples)\n",
    "    \n",
    "    # Isolation Forest zur Erkennung von Ausreißern\n",
    "    OOD_ifo = []\n",
    "    for seed in range(10):\n",
    "        iforest = IsolationForest(random_state=seed).fit(to_sklearn_dataset(X_train))\n",
    "        novelty_detection = iforest.predict(to_sklearn_dataset(counterfactual_examples))\n",
    "        OOD_ifo.append(np.count_nonzero(novelty_detection == -1) / len(counterfactual_examples))\n",
    "    \n",
    "    # Berechne den Durchschnittswert für die OOD-Werte des Isolation Forests\n",
    "    mean_OOD_ifo = np.mean(OOD_ifo)\n",
    "    \n",
    "    return OOD_svm, OOD_lof, mean_OOD_ifo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c4a2e-d804-4491-a604-86a74c2955ec",
   "metadata": {},
   "source": [
    "# Schritt 2: ECG Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452cd93-5b44-44cf-bdcf-28e90ed8a451",
   "metadata": {},
   "source": [
    "## Daten verstehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79d28b-331d-4653-ac07-d6393d54df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11616\\2382496249.py:8: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_train = pd.read_csv(path_Train, header=None, delim_whitespace=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11616\\2382496249.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_test = pd.read_csv(path_Test, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>dataset</td>\n",
       "      <td>was</td>\n",
       "      <td>formatted</td>\n",
       "      <td>by</td>\n",
       "      <td>R.</td>\n",
       "      <td>Olszewski</td>\n",
       "      <td>as</td>\n",
       "      <td>part</td>\n",
       "      <td>of</td>\n",
       "      <td>his</td>\n",
       "      <td>thesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Generalized</td>\n",
       "      <td>feature</td>\n",
       "      <td>extraction</td>\n",
       "      <td>for</td>\n",
       "      <td>structural</td>\n",
       "      <td>pattern</td>\n",
       "      <td>recognition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>time-series</td>\n",
       "      <td>data,”</td>\n",
       "      <td>at</td>\n",
       "      <td>Carnegie</td>\n",
       "      <td>Mellon</td>\n",
       "      <td>University,</td>\n",
       "      <td>2001.</td>\n",
       "      <td>Each</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>series</td>\n",
       "      <td>traces</td>\n",
       "      <td>the</td>\n",
       "      <td>electrical</td>\n",
       "      <td>activity</td>\n",
       "      <td>recorded</td>\n",
       "      <td>during</td>\n",
       "      <td>one</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heartbeat.</td>\n",
       "      <td>The</td>\n",
       "      <td>two</td>\n",
       "      <td>classes</td>\n",
       "      <td>are</td>\n",
       "      <td>a</td>\n",
       "      <td>normal</td>\n",
       "      <td>heartbeat</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>Myocardial</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1           2           3           4         5   \\\n",
       "0          This      dataset         was   formatted          by        R.   \n",
       "1  “Generalized      feature  extraction         for  structural   pattern   \n",
       "2            in  time-series      data,”          at    Carnegie    Mellon   \n",
       "3        series       traces         the  electrical    activity  recorded   \n",
       "4    heartbeat.          The         two     classes         are         a   \n",
       "\n",
       "            6          7     8    9           10      11  \n",
       "0    Olszewski         as  part   of         his  thesis  \n",
       "1  recognition        NaN   NaN  NaN         NaN     NaN  \n",
       "2  University,      2001.  Each  NaN         NaN     NaN  \n",
       "3       during        one   NaN  NaN         NaN     NaN  \n",
       "4       normal  heartbeat   and    a  Myocardial     NaN  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_Train = r\"C:\\Users\\Admin\\Downloads\\ECG200\\ECG200_TRAIN.txt\"\n",
    "path_Test = r\"C:\\Users\\Admin\\Downloads\\ECG200\\ECG200.txt\"\n",
    "\n",
    "\n",
    "# Lese die CSV Datei ein (oder TXT falls das Format Tabulator- oder Leerzeichengetrennt ist)\n",
    "df_train = pd.read_csv(path_Train, header=None, delim_whitespace=True)\n",
    "df_test = pd.read_csv(path_Test, header=None, delim_whitespace=True)\n",
    "\n",
    "# Anzeigen der ersten Zeilen\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668c6c9-ee35-4cf2-bc0a-e26fa4ccab4f",
   "metadata": {},
   "source": [
    "## Pakete importieren für Modell\n",
    "\n",
    "Hier für einen RandomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e99022-fde7-431d-9bba-f698036e6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ed5fb-e1ed-49d7-b1cb-e4982a3e088a",
   "metadata": {},
   "source": [
    "## konkreten Datensatz importieren\n",
    "\n",
    "https://www.cs.ucr.edu/~eamonn/time_series_data_2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6baa3-4104-4968-a436-90694d2d57aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class Naive_Shapelet:\n",
    "    def __init__(self, method='naive_shapelet', DS_name='ECG200'):\n",
    "        self.method = method\n",
    "        self.DS_name = DS_name\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = read_data(DS=self.DS_name)\n",
    "        \n",
    "        \n",
    "        # Build and compile the autoencoder model\n",
    "        print(f\"Shape of X_train before model building: {self.X_train.shape}\")\n",
    "        # Print shapes for debugging\n",
    "        print(f\"Initial X_train shape: {self.X_train.shape}\")\n",
    "        print(f\"Initial X_test shape: {self.X_test.shape}\")\n",
    "\n",
    "        # If the data has only 2 dimensions (samples, timesteps), add a feature dimension\n",
    "        if len(self.X_train.shape) == 2:\n",
    "            self.X_train = np.expand_dims(self.X_train, axis=-1)\n",
    "            self.X_test = np.expand_dims(self.X_test, axis=-1)\n",
    "            print(f\"Adjusted X_train shape: {self.X_train.shape}\")\n",
    "            print(f\"Adjusted X_test shape: {self.X_test.shape}\")\n",
    "        \n",
    "        # If data has only 1 dimension, it might be problematic\n",
    "        elif len(X_train.shape) == 1:\n",
    "            raise ValueError(\"X_train should have at least 2 dimensions. Please check your data loading.\")\n",
    "        print(f\"Shape of X_train before model building: {self.X_train.shape}\")\n",
    "\n",
    "        self.autoencoder = self.build_autoencoder()\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        self.train_autoencoder()\n",
    "        \n",
    "        # Build and compile the classifier model\n",
    "        self.classifier = self.build_classifier()\n",
    "        self.classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the classifier\n",
    "        self.train_classifier()\n",
    "        \n",
    "        # Display dataset information\n",
    "        self.display_dataset_info()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def build_autoencoder(self):\n",
    "        # Print the shape of the input\n",
    "        print(f\"Shape of X_train before model building: {self.X_train.shape}\")\n",
    "\n",
    "        input_shape = (self.X_train.shape[1], self.X_train.shape[2])  # (timesteps, features)\n",
    "\n",
    "        # Encoder\n",
    "        encoder = keras.Sequential([\n",
    "            keras.layers.Input(shape=input_shape),\n",
    "            keras.layers.Conv1D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
    "            keras.layers.Dropout(rate=0.2),\n",
    "            keras.layers.Conv1D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(50, activation='relu')  # Ensure this matches classifier input\n",
    "        ])\n",
    "        \n",
    "        # Decoder\n",
    "        decoder = keras.Sequential([\n",
    "            keras.layers.Dense(24*8, activation='relu'),  # Adjust to match encoder output\n",
    "            keras.layers.Reshape((24, 8)),  # Adjust based on Dense layer output\n",
    "            keras.layers.Conv1DTranspose(filters=8, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            keras.layers.Conv1DTranspose(filters=16, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
    "            keras.layers.Conv1DTranspose(filters=input_shape[1], kernel_size=1, padding='same')\n",
    "        ])\n",
    "        \n",
    "        # Autoencoder model\n",
    "        autoencoder = keras.Sequential([encoder, decoder])\n",
    "        self.encoder = encoder  # Keep a reference to the encoder part\n",
    "        \n",
    "        autoencoder.summary()  # Print the model summary for debugging\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "\n",
    "    def build_classifier(self):\n",
    "        classifier = keras.Sequential([\n",
    "            keras.layers.Input(shape=(50,)),  # Input shape matches the encoder's output\n",
    "            keras.layers.Dense(100, activation='relu'),\n",
    "            keras.layers.Dense(50, activation='relu'),\n",
    "            keras.layers.Dense(len(np.unique(self.y_train)), activation='softmax')\n",
    "        ])\n",
    "        return classifier\n",
    "\n",
    "    def train_autoencoder(self, epochs=50, batch_size=32):\n",
    "        # Train the autoencoder\n",
    "        self.autoencoder.fit(self.X_train, self.X_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    \n",
    "    def train_classifier(self, epochs=50, batch_size=32):\n",
    "        # Encode the training data using the encoder part of the autoencoder\n",
    "        X_train_encoded = self.encoder.predict(self.X_train)\n",
    "        \n",
    "        # Train the classifier on the encoded features\n",
    "        self.classifier.fit(X_train_encoded, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    \n",
    "    def display_dataset_info(self):\n",
    "        print(f\"Dataset: {self.DS_name}\")\n",
    "        print(f\"Shape of X_train: {self.X_train.shape}\")\n",
    "        print(f\"Shape of y_train: {self.y_train.shape}\")\n",
    "        print(f\"Shape of X_test: {self.X_test.shape}\")\n",
    "        print(f\"Shape of y_test: {self.y_test.shape}\")\n",
    "        print(f\"Number of classes: {len(np.unique(self.y_train))}\")\n",
    "        print(f\"Unique class labels: {np.unique(self.y_train)}\")\n",
    "\n",
    "    def generate_cf(self):\n",
    "        len_ts = self.X_train.shape[1]  # Time steps (96)\n",
    "        classes = np.unique(self.y_test)\n",
    "        nb_classes = len(classes)\n",
    "\n",
    "        print(f\"Zeitreihenlänge: {len_ts}\")\n",
    "        print(f\"Anzahl der Klassen im Testdatensatz: {nb_classes}\")\n",
    "\n",
    "        # Flatten X_train if needed for shapelet extraction\n",
    "        X_train_flattened = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "\n",
    "        idx_shapelets = get_shapelet(X_train_flattened, self.y_train, len_ts)\n",
    "        shapelets = [shapelet_category(self.y_train, idx_shapelets, i) for i in classes]\n",
    "\n",
    "        shapelet_dict_list = [{'index': item[0], 'start': item[1], 'end': item[2], 'label': item[3]}\n",
    "                            for sublist in shapelets for item in sublist]\n",
    "        df = pd.DataFrame(shapelet_dict_list)\n",
    "        df.to_csv(f'{self.DS_name}_shapelet.csv', index=True)\n",
    "\n",
    "        for i in range(nb_classes):\n",
    "            plot_shapelet(self.X_train, shapelets, i, save_path=f'{self.DS_name}_{i}_shapelet.png')\n",
    "\n",
    "        model = train_model(self.classifier, self.X_train, self.y_train, self.X_test)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        y_preds = model.predict_proba(self.X_test)\n",
    "        targets = targets_generation(y_preds)\n",
    "        accuracy = eval_model(self.y_test, y_pred)\n",
    "\n",
    "        counterfactual_examples = counterfacutal_generation(self.X_test, shapelets, targets, self.X_train)\n",
    "        np.save(f'{self.DS_name}_{self.method}_cf.npy', counterfactual_examples)\n",
    "        flip_accuracy = check_fliplabel(counterfactual_examples, model, targets)\n",
    "\n",
    "        print(f\"flip_accuracy: {flip_accuracy}\")\n",
    "        return counterfactual_examples, accuracy, model, targets, flip_accuracy\n",
    "\n",
    "   # Methode zum Plotten des Vergleichs von Original- und Gegenbeispielen\n",
    "    def plot_comparison_res(self, index):\n",
    "        counterfactual_examples = np.load(f'{self.DS_name}_{self.method}_cf.npy')\n",
    "        plot_cf_vs_ori(self.DS_name, index, counterfactual_examples, save_path=f'{self.DS_name}_{self.method}_cfVori_fig.png')\n",
    "\n",
    "    def save_res(self):\n",
    "        counterfactual_examples, accuracy, model, targets, flip_accuracy = self.generate_cf()\n",
    "        print(\"Model object:\", model)\n",
    "\n",
    "        if counterfactual_examples is not None:\n",
    "            print(\"Counterfactual examples shape for prediction:\", counterfactual_examples.shape)\n",
    "            try:\n",
    "                counter_res = model.predict(counterfactual_examples)\n",
    "                target_probs = target_probability(counter_res, targets)\n",
    "                cf_eval_res(self.DS_name, self.method, model, accuracy, counterfactual_examples, targets, target_probs)\n",
    "            except Exception as e:\n",
    "                print(\"Error during prediction:\", e)\n",
    "        else:\n",
    "            print(\"No counterfactual examples generated. Results not saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c13d6470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.8663 - val_loss: 0.3343\n",
      "Epoch 2/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3172 - val_loss: 0.1909\n",
      "Epoch 3/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1734 - val_loss: 0.1721\n",
      "Epoch 4/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1776 - val_loss: 0.1394\n",
      "Epoch 5/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1579 - val_loss: 0.1208\n",
      "Epoch 6/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1319 - val_loss: 0.1347\n",
      "Epoch 7/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1198 - val_loss: 0.1181\n",
      "Epoch 8/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1168 - val_loss: 0.1039\n",
      "Epoch 9/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1189 - val_loss: 0.1061\n",
      "Epoch 10/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1022 - val_loss: 0.0933\n",
      "Epoch 11/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1004 - val_loss: 0.0861\n",
      "Epoch 12/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0872 - val_loss: 0.0887\n",
      "Epoch 13/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0792\n",
      "Epoch 14/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0931\n",
      "Epoch 15/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0799 - val_loss: 0.0841\n",
      "Epoch 16/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0791\n",
      "Epoch 17/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0760 - val_loss: 0.1029\n",
      "Epoch 18/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0779\n",
      "Epoch 19/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0747\n",
      "Epoch 20/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0733 - val_loss: 0.0774\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.7063 - loss: 0.8379 - val_accuracy: 0.5500 - val_loss: 0.9047\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7375 - loss: 0.5124 - val_accuracy: 0.5500 - val_loss: 0.6669\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7867 - loss: 0.3892 - val_accuracy: 0.7000 - val_loss: 0.5661\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8086 - loss: 0.3390 - val_accuracy: 0.7500 - val_loss: 0.5269\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8344 - loss: 0.2951 - val_accuracy: 0.7500 - val_loss: 0.5154\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8414 - loss: 0.2871 - val_accuracy: 0.7500 - val_loss: 0.5288\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8969 - loss: 0.2401 - val_accuracy: 0.8000 - val_loss: 0.5478\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9133 - loss: 0.2352 - val_accuracy: 0.8000 - val_loss: 0.5581\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9016 - loss: 0.2413 - val_accuracy: 0.8000 - val_loss: 0.5656\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9195 - loss: 0.2128 - val_accuracy: 0.7500 - val_loss: 0.5639\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.1794 - val_accuracy: 0.8000 - val_loss: 0.5259\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1953 - val_accuracy: 0.8500 - val_loss: 0.4852\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9555 - loss: 0.1810 - val_accuracy: 0.8000 - val_loss: 0.4786\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9555 - loss: 0.1599 - val_accuracy: 0.8000 - val_loss: 0.4847\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9555 - loss: 0.1659 - val_accuracy: 0.8000 - val_loss: 0.5005\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9195 - loss: 0.1604 - val_accuracy: 0.7500 - val_loss: 0.5122\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9273 - loss: 0.1611 - val_accuracy: 0.8000 - val_loss: 0.4929\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1420 - val_accuracy: 0.8000 - val_loss: 0.4815\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9672 - loss: 0.1164 - val_accuracy: 0.8000 - val_loss: 0.4673\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9555 - loss: 0.1374 - val_accuracy: 0.8000 - val_loss: 0.4488\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9438 - loss: 0.1478 - val_accuracy: 0.8000 - val_loss: 0.4489\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9438 - loss: 0.1352 - val_accuracy: 0.8000 - val_loss: 0.4522\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9633 - loss: 0.1255 - val_accuracy: 0.8000 - val_loss: 0.4621\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9539 - loss: 0.1410 - val_accuracy: 0.8000 - val_loss: 0.4592\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9539 - loss: 0.1269 - val_accuracy: 0.8000 - val_loss: 0.4556\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9617 - loss: 0.1149 - val_accuracy: 0.8000 - val_loss: 0.4460\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9617 - loss: 0.1243 - val_accuracy: 0.8000 - val_loss: 0.4477\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9656 - loss: 0.1029 - val_accuracy: 0.8000 - val_loss: 0.4414\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9695 - loss: 0.1053 - val_accuracy: 0.8000 - val_loss: 0.4376\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9758 - loss: 0.1070 - val_accuracy: 0.8000 - val_loss: 0.4328\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9719 - loss: 0.1118 - val_accuracy: 0.8000 - val_loss: 0.4325\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9758 - loss: 0.0815 - val_accuracy: 0.8000 - val_loss: 0.4362\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9797 - loss: 0.0914 - val_accuracy: 0.8000 - val_loss: 0.4408\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9695 - loss: 0.0858 - val_accuracy: 0.8000 - val_loss: 0.4321\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9719 - loss: 0.0945 - val_accuracy: 0.8000 - val_loss: 0.4147\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9836 - loss: 0.0909 - val_accuracy: 0.8000 - val_loss: 0.4102\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9719 - loss: 0.0884 - val_accuracy: 0.8000 - val_loss: 0.4099\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0885 - val_accuracy: 0.8000 - val_loss: 0.4193\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9641 - loss: 0.0852 - val_accuracy: 0.8500 - val_loss: 0.4368\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9719 - loss: 0.0881 - val_accuracy: 0.8000 - val_loss: 0.4276\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9641 - loss: 0.0964 - val_accuracy: 0.8000 - val_loss: 0.4060\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0785 - val_accuracy: 0.8000 - val_loss: 0.3976\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9937 - loss: 0.0545 - val_accuracy: 0.8000 - val_loss: 0.3955\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9820 - loss: 0.0753 - val_accuracy: 0.8500 - val_loss: 0.3902\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9898 - loss: 0.0658 - val_accuracy: 0.9000 - val_loss: 0.3970\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9641 - loss: 0.0885 - val_accuracy: 0.9000 - val_loss: 0.4004\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9758 - loss: 0.0663 - val_accuracy: 0.8500 - val_loss: 0.3915\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9719 - loss: 0.0612 - val_accuracy: 0.8000 - val_loss: 0.3788\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0631 - val_accuracy: 0.8000 - val_loss: 0.3864\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9898 - loss: 0.0505 - val_accuracy: 0.8500 - val_loss: 0.3938\n",
      "Dataset: ECG200\n",
      "Shape of X_train: (100, 96, 1)\n",
      "Shape of y_train: (100,)\n",
      "Shape of X_test: (100, 96, 1)\n",
      "Shape of y_test: (100,)\n",
      "Number of classes: 2\n",
      "Unique class labels: [0 1]\n",
      "Zeitreihenlänge: 96\n",
      "Anzahl der Klassen im Testdatensatz: 2\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Naive_Shapelet:\n",
    "    def __init__(self, method='naive_shapelet', DS_name='ECG200'):\n",
    "        self.method = method\n",
    "        self.DS_name = DS_name\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = read_data(DS=self.DS_name)\n",
    "        \n",
    "        # Adjust data shape\n",
    "        if len(self.X_train.shape) == 2:\n",
    "            self.X_train = np.expand_dims(self.X_train, axis=-1)\n",
    "            self.X_test = np.expand_dims(self.X_test, axis=-1)\n",
    "        \n",
    "        # Build and compile the autoencoder model\n",
    "        self.encoder, self.autoencoder = self.build_autoencoder()\n",
    "        self.autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        self.train_autoencoder()\n",
    "        \n",
    "        # Build and compile the classifier model\n",
    "        self.classifier = self.build_classifier()\n",
    "        self.classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the classifier\n",
    "        self.train_classifier()\n",
    "        \n",
    "        # Display dataset information\n",
    "        self.display_dataset_info()\n",
    "\n",
    "    def build_autoencoder(self):\n",
    "        input_shape = (self.X_train.shape[1], self.X_train.shape[2])\n",
    "\n",
    "        # Encoder\n",
    "        encoder_input = keras.Input(shape=input_shape)\n",
    "        x = keras.layers.Conv1D(filters=16, kernel_size=5, strides=2, padding='same', activation='relu')(encoder_input)\n",
    "        x = keras.layers.Dropout(rate=0.2)(x)\n",
    "        x = keras.layers.Conv1D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        encoder_output = keras.layers.Dense(50, activation='relu')(x)\n",
    "\n",
    "        encoder = keras.Model(inputs=encoder_input, outputs=encoder_output, name=\"encoder\")\n",
    "\n",
    "        intermediate_shape = (input_shape[0] // 4, 8)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_input = keras.Input(shape=(50,))\n",
    "        x = keras.layers.Dense(np.prod(intermediate_shape), activation='relu')(decoder_input)\n",
    "        x = keras.layers.Reshape(intermediate_shape)(x)\n",
    "        x = keras.layers.Conv1DTranspose(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Dropout(rate=0.2)(x)\n",
    "        x = keras.layers.Conv1DTranspose(filters=16, kernel_size=5, strides=2, padding='same', activation='relu')(x)\n",
    "        decoder_output = keras.layers.Conv1DTranspose(filters=input_shape[1], kernel_size=5, padding='same')(x)\n",
    "\n",
    "        decoder = keras.Model(inputs=decoder_input, outputs=decoder_output, name=\"decoder\")\n",
    "\n",
    "        # Autoencoder model\n",
    "        autoencoder_input = keras.Input(shape=input_shape)\n",
    "        encoded = encoder(autoencoder_input)\n",
    "        decoded = decoder(encoded)\n",
    "        autoencoder = keras.Model(inputs=autoencoder_input, outputs=decoded, name=\"autoencoder\")\n",
    "\n",
    "        return encoder, autoencoder\n",
    "\n",
    "    def train_autoencoder(self, epochs=20, batch_size=1):\n",
    "        history = self.autoencoder.fit(\n",
    "            self.X_train,\n",
    "            self.X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')]\n",
    "        )\n",
    "\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def build_classifier(self):\n",
    "        classifier = keras.Sequential([\n",
    "            keras.layers.Input(shape=(50,)),  # Input shape matches the encoder's output\n",
    "            keras.layers.Dense(100, activation='relu'),\n",
    "            keras.layers.Dense(50, activation='relu'),\n",
    "            keras.layers.Dense(len(np.unique(self.y_train)), activation='softmax')\n",
    "        ])\n",
    "        return classifier\n",
    "\n",
    "    def train_classifier(self, epochs=50, batch_size=32):\n",
    "        X_train_encoded = self.encoder.predict(self.X_train)\n",
    "        self.classifier.fit(X_train_encoded, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    \n",
    "    def display_dataset_info(self):\n",
    "        print(f\"Dataset: {self.DS_name}\")\n",
    "        print(f\"Shape of X_train: {self.X_train.shape}\")\n",
    "        print(f\"Shape of y_train: {self.y_train.shape}\")\n",
    "        print(f\"Shape of X_test: {self.X_test.shape}\")\n",
    "        print(f\"Shape of y_test: {self.y_test.shape}\")\n",
    "        print(f\"Number of classes: {len(np.unique(self.y_train))}\")\n",
    "        print(f\"Unique class labels: {np.unique(self.y_train)}\")\n",
    "\n",
    "   \n",
    "    def generate_cf(self):\n",
    "        len_ts = self.X_train.shape[1]  # Time steps (96)\n",
    "        classes = np.unique(self.y_test)\n",
    "        nb_classes = len(classes)\n",
    "\n",
    "        print(f\"Zeitreihenlänge: {len_ts}\")\n",
    "        print(f\"Anzahl der Klassen im Testdatensatz: {nb_classes}\")\n",
    "\n",
    "        # Flatten X_train if needed for shapelet extraction\n",
    "        X_train_flattened = self.X_train.reshape(self.X_train.shape[0], -1)\n",
    "\n",
    "        idx_shapelets = get_shapelet(X_train_flattened, self.y_train, len_ts)\n",
    "        shapelets = [shapelet_category(self.y_train, idx_shapelets, i) for i in classes]\n",
    "\n",
    "        shapelet_dict_list = [{'index': item[0], 'start': item[1], 'end': item[2], 'label': item[3]}\n",
    "                            for sublist in shapelets for item in sublist]\n",
    "        df = pd.DataFrame(shapelet_dict_list)\n",
    "        df.to_csv(f'{self.DS_name}_shapelet.csv', index=True)\n",
    "\n",
    "        for i in range(nb_classes):\n",
    "            plot_shapelet(self.X_train, shapelets, i, save_path=f'{self.DS_name}_{i}_shapelet.png')\n",
    "\n",
    "        model = train_model(self.classifier, self.X_train, self.y_train, self.X_test)\n",
    "\n",
    "        # Encode the test data before making predictions\n",
    "        X_test_encoded = self.encoder.predict(self.X_test)\n",
    "\n",
    "        # Ensure X_test_encoded has the correct shape\n",
    "        if X_test_encoded.shape[1:] != (50,):\n",
    "            raise ValueError(\"Encoded X_test does not have the expected shape\")\n",
    "\n",
    "        # Predict class probabilities\n",
    "        y_preds_prob = model.predict(X_test_encoded)\n",
    "\n",
    "        # Ensure y_preds_prob has the correct shape\n",
    "        if y_preds_prob.shape[1] != len(np.unique(self.y_train)):\n",
    "            raise ValueError(\"Prediction probabilities do not match the number of classes\")\n",
    "\n",
    "        # Convert probabilities to class labels\n",
    "        y_pred = np.argmax(y_preds_prob, axis=1)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "\n",
    "        # Erhalte Vorhersagen und Wahrscheinlichkeiten\n",
    "        y_preds = model.predict_proba(X_test_encoded)  # Ensure correct function usage\n",
    "        targets = targets_generation(y_preds_prob)  # Modify if necessary\n",
    "        counterfactual_examples = counterfacutal_generation(self.X_test, shapelets, targets, self.X_train)\n",
    "        print(\"Model input shape:\", model.input_shape)\n",
    "\n",
    "        print(f\"Shape of counterfactual_examples: {counterfactual_examples.shape}\")\n",
    "\n",
    "        np.save(f'{self.DS_name}_{self.method}_cf.npy', counterfactual_examples)\n",
    "        flip_accuracy = self.check_fliplabel(counterfactual_examples, model, targets)\n",
    "\n",
    "        print(f\"flip_accuracy: {flip_accuracy}\")\n",
    "        return counterfactual_examples, accuracy, model, targets, flip_accuracy\n",
    "\n",
    "\n",
    "    def plot_comparison_res(self, index):\n",
    "        counterfactual_examples = np.load(f'{self.DS_name}_{self.method}_cf.npy')\n",
    "        plot_cf_vs_ori(self.DS_name, index, counterfactual_examples, save_path=f'{self.DS_name}_{self.method}_cfVori_fig.png')\n",
    "\n",
    "    def reshape_for_model(self, counterfactual_examples, target_shape):\n",
    "        num_samples = counterfactual_examples.shape[0]\n",
    "        \n",
    "        # Flatten counterfactual_examples to 2D if necessary\n",
    "        flattened = np.reshape(counterfactual_examples, (num_samples, -1))\n",
    "        print(f\"Flattened shape: {flattened.shape}\")\n",
    "\n",
    "        # Adjust the reshaping logic\n",
    "        target_dim = target_shape[0]  # Should be 50 in this case\n",
    "\n",
    "        if flattened.shape[1] > target_dim:\n",
    "            # Truncate if necessary\n",
    "            reshaped = flattened[:, :target_dim]\n",
    "        elif flattened.shape[1] < target_dim:\n",
    "            # Pad with zeros if necessary\n",
    "            padding = target_dim - flattened.shape[1]\n",
    "            reshaped = np.pad(flattened, ((0, 0), (0, padding)), mode='constant')\n",
    "        else:\n",
    "            reshaped = flattened\n",
    "        \n",
    "        print(f\"Reshaped shape: {reshaped.shape}\")\n",
    "        \n",
    "        return reshaped\n",
    "\n",
    "\n",
    "    def prepare_for_prediction(self, counterfactual_examples, model):\n",
    "        # Convert to TensorFlow tensor\n",
    "        counterfactual_examples = tf.convert_to_tensor(counterfactual_examples, dtype=tf.float32)\n",
    "        \n",
    "        # Model input shape\n",
    "        model_input_shape = model.input_shape\n",
    "        print(f\"Model input shape: {model_input_shape}\")\n",
    "        \n",
    "        if len(model_input_shape) > 1:\n",
    "            target_shape = model_input_shape[1:]  # Exclude the batch dimension\n",
    "        else:\n",
    "            target_shape = (model_input_shape[0],)  # Handle single dimension case\n",
    "        \n",
    "        # Print target shape for debugging\n",
    "        print(f\"Target shape: {target_shape}\")\n",
    "        \n",
    "        # Reshape\n",
    "        reshaped_examples = self.reshape_for_model(counterfactual_examples, target_shape)\n",
    "        \n",
    "        return reshaped_examples\n",
    "\n",
    "\n",
    "\n",
    "    def check_fliplabel(self, counterfactual_examples, model, targets):\n",
    "        reshaped_examples = self.prepare_for_prediction(counterfactual_examples, model)\n",
    "        \n",
    "        # Make predictions\n",
    "        counter_res = model.predict(reshaped_examples)\n",
    "        \n",
    "        print(f\"Predictions shape: {counter_res.shape}\")\n",
    "        \n",
    "        # Example computation for flip_accuracy\n",
    "        # You need to define what flip_accuracy means for your use case\n",
    "        flip_accuracy = np.mean(np.argmax(counter_res, axis=-1) != targets)\n",
    "        \n",
    "        return flip_accuracy\n",
    "\n",
    "    def save_res(self):\n",
    "        counterfactual_examples, accuracy, model, targets, flip_accuracy = self.generate_cf()\n",
    "        print(\"Model object:\", model)\n",
    "        print(f\"Shape of counterfactual_examples: {counterfactual_examples.shape}\")\n",
    "        \n",
    "        np.save(f'{self.DS_name}_{self.method}_cf.npy', counterfactual_examples)\n",
    "        \n",
    "        # Debugging print statements\n",
    "        print(f\"Counterfactual examples shape: {counterfactual_examples.shape}\")\n",
    "        print(f\"Model input shape: {model.input_shape}\")\n",
    "        \n",
    "        flip_accuracy = self.check_fliplabel(counterfactual_examples, model, targets)\n",
    "        print(f\"flip_accuracy: {flip_accuracy}\")\n",
    "        counter_res = model.predict_proba(counterfactual_examples)\n",
    "        target_probs = target_probability(counter_res, targets)\n",
    "        cf_eval_res(self.DS_name, self.method, model, accuracy, counterfactual_examples, targets, target_probs)\n",
    "\n",
    "        \n",
    "        return counterfactual_examples, accuracy, model, targets, flip_accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    naive_shapelet_instance = Naive_Shapelet()\n",
    "    naive_shapelet_instance.save_res()\n",
    "    naive_shapelet_instance.plot_comparison_res(index=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb313847-172f-410f-936f-b2fcc619e8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_transpose_96\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     naive_shapelet_instance\u001b[38;5;241m.\u001b[39mplot_comparison_res(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[239], line 4\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Erstelle eine Instanz der Naive_Shapelet-Klasse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     naive_shapelet_instance \u001b[38;5;241m=\u001b[39m \u001b[43mNaive_Shapelet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Rufe save_res auf, um die Ergebnisse zu speichern\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     naive_shapelet_instance\u001b[38;5;241m.\u001b[39msave_res()\n",
      "Cell \u001b[1;32mIn[238], line 20\u001b[0m, in \u001b[0;36mNaive_Shapelet.__init__\u001b[1;34m(self, method, DS_name)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Build and compile the autoencoder model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the autoencoder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[238], line 67\u001b[0m, in \u001b[0;36mNaive_Shapelet.build_autoencoder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m decoder \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     58\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(np\u001b[38;5;241m.\u001b[39mprod(encoder_output_shape), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     59\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReshape(encoder_output_shape),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1DTranspose(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m ])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Autoencoder model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m autoencoder\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:75\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:146\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[1;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:186\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:202\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmin_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         )\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv1d_transpose_96\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 50)"
     ]
    }
   ],
   "source": [
    "# Hauptfunktion zur Ausführung des Naive_Shapelet-Prozesses\n",
    "def main():\n",
    "    # Erstelle eine Instanz der Naive_Shapelet-Klasse\n",
    "    naive_shapelet_instance = Naive_Shapelet()\n",
    "\n",
    "    # Rufe save_res auf, um die Ergebnisse zu speichern\n",
    "    naive_shapelet_instance.save_res()\n",
    "    \n",
    "    # Plotte den Vergleich von Original und Gegenbeispiel\n",
    "    naive_shapelet_instance.plot_comparison_res(index=-1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
